"""
Script to analyze embeddings generated by AION, AstroPT, and AstroCLIP models.
It computes and visualizes:
- UMAP projections of embeddings.
- Cosine similarities between different embedding modalities (e.g., HSC vs DESI, or AION vs AstroCLIP).
- Nearest neighbor agreement between modalities.

Usage:
    python -m scratch.analyze_embeddings \
        --aion-embeddings /path/to/aion.pt \
        --astropt-embeddings /path/to/astropt.pt \
        --astroclip-embeddings /path/to/astroclip.pt \
        --figure umap.png \
        --cosine-figure cosine_hist.png --nn-figure nn_agreement.png
"""
import argparse
import csv
import math
from pathlib import Path
from typing import Sequence

import matplotlib.pyplot as plt
import numpy as np
import torch

try:
    import umap
except ImportError as exc:  # pragma: no cover - defensive
    raise SystemExit(
        "The 'umap-learn' package is required. Install it with 'pip install umap-learn'."
    ) from exc


AION_EMBEDDING_KEYS = [
    "aion_embedding_hsc_desi",
    "aion_embedding_hsc",
    "aion_embedding_spectrum",
]

ASTROPT_EMBEDDING_KEYS = [
    "embedding_images",
    "embedding_spectra",
    "embedding_joint",
]

ASTROCLIP_EMBEDDING_KEYS = [
    "embedding_images",
    "embedding_spectra",
    "embedding_joint",
]

DEFAULT_PAIR = "aion_embedding_hsc_desi,aion_embedding_hsc"


def load_records(path: Path) -> list[dict]:
    data = torch.load(path, map_location="cpu", weights_only=False)
    if isinstance(data, list):
        return data
    if isinstance(data, dict):
        return [data]
    raise ValueError(f"Unsupported embeddings format: {type(data)}")


def merge_records(
    aion_path: Path | None, 
    astropt_path: Path | None, 
    astroclip_path: Path | None
) -> list[dict]:
    """Load and merge records from available files."""
    merged = {}
    
    def _process_file(path: Path, prefix: str = ""):
        if not path: return
        print(f"Loading {path}...")
        recs = load_records(path)
        for r in recs:
            oid = str(r.get("object_id", ""))
            if not oid: continue
            
            if oid not in merged:
                merged[oid] = {"object_id": oid, "redshift": r.get("redshift")}
            
            # If redshift missing in merged, try to add it
            if merged[oid].get("redshift") is None and r.get("redshift") is not None:
                merged[oid]["redshift"] = r.get("redshift")
                
            # Copy embeddings
            for k, v in r.items():
                if k in ["object_id", "redshift"]: continue
                
                # Determine new key name to avoid collision
                # If prefix is set, use it. 
                # Exception: AION keys are usually unique (embedding_hsc...).
                # AstroPT and AstroCLIP share 'embedding_images' etc.
                # So for AstroPT and AstroCLIP, we MUST prefix or they overwrite.
                
                if prefix:
                    new_key = f"{prefix}_{k}"
                else:
                    new_key = k
                    
                merged[oid][new_key] = v

    # Load AION (keep original keys for backward compat where AION keys are widely used)
    # AION keys: embedding_hsc_desi, embedding_hsc, embedding_spectrum
    if aion_path:
        _process_file(aion_path, prefix="aion") 

    # Load AstroPT 
    # Keys: embedding_images, embedding_spectra, embedding_joint
    if astropt_path:
       _process_file(astropt_path, prefix="astropt")
       
    # Load AstroCLIP
    if astroclip_path:
        _process_file(astroclip_path, prefix="astroclip")
        
    return list(merged.values())


def stack_embeddings(records: Sequence[dict], key: str) -> np.ndarray:
    vectors = []
    for rec in records:
        tensor = rec.get(key)
        
        # Fallback for old keys if not prefixed (legacy files might be loaded differently)
        if tensor is None and "_" in key:
            # Maybe it wasn't prefixed in the dict?
            # e.g. user asked for 'embedding_hsc' but it's 'aion_embedding_hsc'
            # Or vice versa.
            # But here we rely on the user passing the correct key name corresponding to how we loaded it.
            pass

        if tensor is None:
            continue
            
        if isinstance(tensor, torch.Tensor):
            vectors.append(tensor.detach().cpu().numpy())
        else:
            vectors.append(np.asarray(tensor))
    if not vectors:
        raise ValueError(f"No embeddings found for key '{key}'")
    return np.stack(vectors, axis=0)


def compute_umap(embeddings: np.ndarray, random_state: int) -> np.ndarray:
    reducer = umap.UMAP(random_state=random_state)
    return reducer.fit_transform(embeddings)


def plot_umap_grid(coords_map: dict[str, np.ndarray], colors: np.ndarray | None, save_path: Path) -> None:
    names = sorted(list(coords_map.keys()))
    n_plots = len(names)
    cols = min(4, n_plots) # Up to 4 columns
    rows = math.ceil(n_plots / cols)
    
    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))
    if n_plots == 1:
        axes = [axes]
    elif rows > 1 or cols > 1:
        axes = axes.flatten()
        
    for i, name in enumerate(names):
        ax = axes[i]
        coords = coords_map[name]
        if colors is not None:
            mask = ~np.isnan(colors)
            scatter = ax.scatter(
                coords[mask, 0],
                coords[mask, 1],
                c=colors[mask],
                cmap="viridis",
                s=6,
            )
            fig.colorbar(scatter, ax=ax, label="Redshift")
            if (~mask).any():
                ax.scatter(
                    coords[~mask, 0],
                    coords[~mask, 1],
                    s=6,
                    color="lightgray",
                    alpha=0.5,
                    label="redshift NA",
                )
        else:
            ax.scatter(coords[:, 0], coords[:, 1], s=6, color="royalblue", alpha=0.7)
        pretty = name.replace("embedding_", "").replace("_", " ").upper()
        ax.set_title(pretty, fontsize=10)
        ax.set_xlabel("UMAP-1")
        ax.set_ylabel("UMAP-2")
        ax.grid(True, alpha=0.2)
        
    # Hide unused axes
    if hasattr(axes, '__len__'):
        for j in range(i + 1, len(axes)):
            axes[j].axis('off')

    fig.suptitle("UMAP projections", fontsize=16)
    fig.tight_layout()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(save_path, dpi=200)
    plt.close(fig)


def compute_cosine_similarities(records: Sequence[dict], key_a: str, key_b: str) -> np.ndarray:
    sims = []
    for rec in records:
        emb_a = rec.get(key_a)
        emb_b = rec.get(key_b)
        if emb_a is None or emb_b is None:
            continue
        if isinstance(emb_a, torch.Tensor):
            emb_a = emb_a.detach().cpu()
        else:
            emb_a = torch.as_tensor(emb_a)
        if isinstance(emb_b, torch.Tensor):
            emb_b = emb_b.detach().cpu()
        else:
            emb_b = torch.as_tensor(emb_b)
        emb_a = emb_a.to(torch.float32)
        emb_b = emb_b.to(torch.float32)
        
        # Flatten if needed (e.g. if one is (1, D) and other is (D,))
        if emb_a.shape != emb_b.shape:
             if emb_a.numel() == emb_b.numel():
                 emb_a = emb_a.view(-1)
                 emb_b = emb_b.view(-1)
             else:
                continue 
                
        sims.append(
            torch.nn.functional.cosine_similarity(emb_a.unsqueeze(0), emb_b.unsqueeze(0)).item()
        )
    return np.array(sims)


def plot_cosine_distribution(cosine: np.ndarray, save_path: Path) -> None:
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.hist(cosine, bins=40, color="steelblue", alpha=0.8, edgecolor="black")
    ax.set_xlabel("Cosine similarity")
    ax.set_ylabel("Count")
    ax.set_title("Cosine similarity distribution")
    ax.grid(True, alpha=0.2)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.tight_layout()
    fig.savefig(save_path, dpi=200)
    plt.close(fig)


def plot_cosine_vs_redshift(
    cosine: np.ndarray,
    redshift: np.ndarray,
    save_path: Path,
) -> None:
    mask = ~np.isnan(redshift)
    if mask.sum() == 0:
        print("No valid redshift values available for cosine vs redshift plot.")
        return

    fig, ax = plt.subplots(figsize=(6, 4))
    ax.scatter(
        redshift[mask],
        cosine[mask],
        s=10,
        c=cosine[mask],
        cmap="magma",
        alpha=0.7,
        edgecolors="none",
    )
    ax.set_xlabel("Redshift")
    ax.set_ylabel("Cosine similarity")
    ax.set_title("Cosine similarity vs redshift")
    ax.grid(True, alpha=0.2)

    sorted_idx = np.argsort(redshift[mask])
    z_sorted = redshift[mask][sorted_idx]
    cos_sorted = cosine[mask][sorted_idx]
    window = max(5, int(len(z_sorted) * 0.05))
    if window % 2 == 0:
        window += 1
    if window < len(z_sorted):
        kernel = np.ones(window) / window
        smooth = np.convolve(cos_sorted, kernel, mode="valid")
        center = (window - 1) // 2
        ax.plot(z_sorted[center : center + len(smooth)], smooth, color="white", linewidth=2.0, alpha=0.8)

    fig.tight_layout()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(save_path, dpi=200)
    plt.close(fig)


def _nearest_neighbor_indices(embeddings: np.ndarray) -> np.ndarray:
    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
    norms[norms == 0] = 1e-9
    normalized = embeddings / norms
    similarity = normalized @ normalized.T
    np.fill_diagonal(similarity, -np.inf)
    return np.argmax(similarity, axis=1)


def compute_nearest_neighbor_agreement(
    emb_a: np.ndarray,
    emb_b: np.ndarray,
) -> tuple[np.ndarray, np.ndarray, float]:
    nn_a = _nearest_neighbor_indices(emb_a)
    nn_b = _nearest_neighbor_indices(emb_b)
    matches = nn_a == nn_b
    match_ratio = matches.mean() if matches.size else math.nan
    return matches, np.stack((nn_a, nn_b), axis=1), match_ratio


def plot_nn_agreement(matches: np.ndarray, save_path: Path) -> None:
    counts = np.array([matches.sum(), (~matches).sum()])
    labels = ["Same neighbor", "Different neighbor"]
    fig, ax = plt.subplots(figsize=(6, 4))
    bars = ax.bar(labels, counts, color=["seagreen", "salmon"], alpha=0.8)
    ax.set_ylabel("Number of objects")
    ax.set_title("Nearest-neighbor agreement")
    for bar, count in zip(bars, counts):
        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(int(count)), ha="center", va="bottom")
    ax.grid(axis="y", alpha=0.2)
    fig.tight_layout()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(save_path, dpi=200)
    plt.close(fig)


def parse_pair(value: str) -> tuple[str, str]:
    parts = [p.strip() for p in value.split(",") if p.strip()]
    if len(parts) != 2:
        raise argparse.ArgumentTypeError("Pair must contain exactly two embedding keys separated by a comma")
    return parts[0], parts[1]


def main(argv: Sequence[str] | None = None) -> None:
    parser = argparse.ArgumentParser(
        description="UMAP projections, cosine similarities, and nearest-neighbor diagnostics for embeddings",
    )
    # Inputs (at least one required)
    parser.add_argument("--aion-embeddings", help="Path to AION embeddings .pt file")
    parser.add_argument("--astropt-embeddings", help="Path to AstroPT embeddings .pt file")
    parser.add_argument("--astroclip-embeddings", help="Path to AstroCLIP embeddings .pt file")
    parser.add_argument("--input", help="Legacy argument: Path to embeddings .pt file")
    
    parser.add_argument("--figure", required=True, help="Path to save UMAP figure")
    parser.add_argument("--cosine-output", default=None, help="Optional path to save cosine similarities (.csv/.npy)")
    parser.add_argument("--cosine-figure", default=None, help="Optional path to save cosine histogram")
    parser.add_argument("--cosine-redshift-figure", default=None, help="Optional path for cosine vs redshift plot")
    parser.add_argument("--nn-figure", default=None, help="Optional path for nearest-neighbor agreement figure")
    parser.add_argument("--nn-report", default=None, help="Optional CSV path for nearest-neighbor pairs")
    parser.add_argument(
        "--cosine-pair",
        type=parse_pair,
        default=parse_pair(DEFAULT_PAIR),
        help=f"Embedding pair for cosine metrics (default: {DEFAULT_PAIR})",
    )
    parser.add_argument(
        "--nn-pair",
        type=parse_pair,
        default=parse_pair(DEFAULT_PAIR),
        help=f"Embedding pair for nearest-neighbor metrics (default: {DEFAULT_PAIR})",
    )
    parser.add_argument("--random-state", type=int, default=42, help="Random state for UMAP")

    args = parser.parse_args(argv)

    # Resolve inputs
    aion_path = Path(args.aion_embeddings) if args.aion_embeddings else (Path(args.input) if args.input else None)
    astropt_path = Path(args.astropt_embeddings) if args.astropt_embeddings else None
    astroclip_path = Path(args.astroclip_embeddings) if args.astroclip_embeddings else None
    
    if not any([aion_path, astropt_path, astroclip_path]):
        parser.error("At least one embedding input file must be provided.")

    records = merge_records(aion_path, astropt_path, astroclip_path)
    print(f"Loaded {len(records)} combined records.")

    # Collect available keys
    available_keys = []
    if records:
        available_keys = [k for k in records[0].keys() if k not in ["object_id", "redshift"]]
    
    print(f"Available embedding keys: {available_keys}")

    embeddings = {}
    for key in available_keys:
        try:
            embeddings[key] = stack_embeddings(records, key)
        except ValueError:
            continue
            
    if not embeddings:
        raise SystemExit("No embeddings found in input file(s)")

    coords_map = {
        key: compute_umap(array, random_state=args.random_state)
        for key, array in embeddings.items()
    }

    redshifts = np.array([rec.get("redshift", np.nan) for rec in records], dtype=float)
    colors = redshifts.copy()
    if np.isnan(colors).all():
        colors = None

    plot_umap_grid(coords_map, colors, Path(args.figure))

    key_a, key_b = args.cosine_pair
    
    # Validation for pairs
    if key_a not in embeddings or key_b not in embeddings:
         print(f"Warning: Requested pairs {key_a}, {key_b} not found in data. Skipping cosine/NN analysis. Available keys are: {list(embeddings.keys())}")
    else: 
        cosine = compute_cosine_similarities(records, key_a, key_b)
        print(
            f"Cosine similarity ({key_a} vs {key_b}) -- mean: {cosine.mean():.4f}  std: {cosine.std():.4f}  "
            f"min: {cosine.min():.4f}  max: {cosine.max():.4f}"
        )

        if args.cosine_output:
            cosine_path = Path(args.cosine_output)
            cosine_path.parent.mkdir(parents=True, exist_ok=True)
            object_ids = [rec.get("object_id", "") for rec in records]
            if cosine_path.suffix.lower() == ".csv":
                with cosine_path.open("w", newline="") as csvfile:
                    writer = csv.writer(csvfile)
                    writer.writerow(["object_id", f"cosine_{key_a}_vs_{key_b}"])
                    for oid, cos_val in zip(object_ids, cosine):
                        writer.writerow([oid, f"{cos_val:.6f}"])
            else:
                np.save(cosine_path, cosine)
            print(f"Saved cosine similarities to {cosine_path}")

        if args.cosine_figure:
            plot_cosine_distribution(cosine, Path(args.cosine_figure))
            print(f"Saved cosine histogram to {args.cosine_figure}")

        if args.cosine_redshift_figure:
            plot_cosine_vs_redshift(cosine, redshifts, Path(args.cosine_redshift_figure))
            print(f"Saved cosine vs redshift figure to {args.cosine_redshift_figure}")

        if args.nn_figure or args.nn_report:
            nn_a, nn_b = args.nn_pair
            matches, nn_pairs, match_ratio = compute_nearest_neighbor_agreement(
                embeddings[nn_a], embeddings[nn_b]
            )
            print(
                f"Nearest-neighbor agreement ({nn_a} vs {nn_b}): {matches.sum()} / {len(matches)} "
                f"(ratio={match_ratio:.3f})"
            )
            if args.nn_figure:
                plot_nn_agreement(matches, Path(args.nn_figure))
                print(f"Saved nearest-neighbor agreement figure to {args.nn_figure}")
            if args.nn_report:
                report_path = Path(args.nn_report)
                report_path.parent.mkdir(parents=True, exist_ok=True)
                object_ids = [rec.get("object_id", "") for rec in records]
                with report_path.open("w", newline="") as csvfile:
                    writer = csv.writer(csvfile)
                    writer.writerow(["object_id", f"nn_{nn_a}", f"nn_{nn_b}", "match"])
                    for idx, (nn_idx_a, nn_idx_b) in enumerate(nn_pairs):
                        writer.writerow(
                            [
                                object_ids[idx],
                                object_ids[nn_idx_a],
                                object_ids[nn_idx_b],
                                "True" if matches[idx] else "False",
                            ]
                        )
                print(f"Saved nearest-neighbor report to {report_path}")


if __name__ == "__main__":
    main()
