"""
Script to analyze embeddings generated by the AION model.
It computes and visualizes:
- UMAP projections of embeddings.
- Cosine similarities between different embedding modalities (e.g., HSC vs DESI).
- Nearest neighbor agreement between modalities.

Usage:
    python -m scratch.analyze_embeddings --input /path/to/embeddings.pt --figure umap.png \
        --cosine-figure cosine_hist.png --nn-figure nn_agreement.png
"""
import argparse
import csv
import math
from pathlib import Path
from typing import Sequence

import matplotlib.pyplot as plt
import numpy as np
import torch

try:
    import umap
except ImportError as exc:  # pragma: no cover - defensive
    raise SystemExit(
        "The 'umap-learn' package is required. Install it with 'pip install umap-learn'."
    ) from exc


EMBEDDING_KEYS = [
    "embedding_hsc_desi",
    "embedding_hsc",
    "embedding_spectrum",
]
DEFAULT_PAIR = "embedding_hsc_desi,embedding_hsc"


def load_records(path: Path) -> list[dict]:
    data = torch.load(path, map_location="cpu")
    if isinstance(data, list):
        return data
    if isinstance(data, dict):
        return [data]
    raise ValueError(f"Unsupported embeddings format: {type(data)}")


def stack_embeddings(records: Sequence[dict], key: str) -> np.ndarray:
    vectors = []
    for rec in records:
        tensor = rec.get(key)
        if tensor is None:
            continue
        if isinstance(tensor, torch.Tensor):
            vectors.append(tensor.detach().cpu().numpy())
        else:
            vectors.append(np.asarray(tensor))
    if not vectors:
        raise ValueError(f"No embeddings found for key '{key}'")
    return np.stack(vectors, axis=0)


def compute_umap(embeddings: np.ndarray, random_state: int) -> np.ndarray:
    reducer = umap.UMAP(random_state=random_state)
    return reducer.fit_transform(embeddings)


def plot_umap_grid(coords_map: dict[str, np.ndarray], colors: np.ndarray | None, save_path: Path) -> None:
    names = list(coords_map.keys())
    fig, axes = plt.subplots(1, len(names), figsize=(6 * len(names), 5))
    if len(names) == 1:
        axes = [axes]
    for ax, name in zip(axes, names):
        coords = coords_map[name]
        if colors is not None:
            mask = ~np.isnan(colors)
            scatter = ax.scatter(
                coords[mask, 0],
                coords[mask, 1],
                c=colors[mask],
                cmap="viridis",
                s=6,
            )
            fig.colorbar(scatter, ax=ax, label="Redshift")
            if (~mask).any():
                ax.scatter(
                    coords[~mask, 0],
                    coords[~mask, 1],
                    s=6,
                    color="lightgray",
                    alpha=0.5,
                    label="redshift NA",
                )
                ax.legend(loc="lower left", fontsize=8)
        else:
            ax.scatter(coords[:, 0], coords[:, 1], s=6, color="royalblue", alpha=0.7)
        pretty = name.replace("embedding_", "UMAP â€“ ").replace("_", " ").upper()
        ax.set_title(pretty)
        ax.set_xlabel("UMAP-1")
        ax.set_ylabel("UMAP-2")
        ax.grid(True, alpha=0.2)
    fig.suptitle("UMAP projections of AION embeddings", fontsize=14)
    fig.tight_layout()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(save_path, dpi=200)
    plt.close(fig)


def compute_cosine_similarities(records: Sequence[dict], key_a: str, key_b: str) -> np.ndarray:
    sims = []
    for rec in records:
        emb_a = rec.get(key_a)
        emb_b = rec.get(key_b)
        if emb_a is None or emb_b is None:
            continue
        if isinstance(emb_a, torch.Tensor):
            emb_a = emb_a.detach().cpu()
        else:
            emb_a = torch.as_tensor(emb_a)
        if isinstance(emb_b, torch.Tensor):
            emb_b = emb_b.detach().cpu()
        else:
            emb_b = torch.as_tensor(emb_b)
        emb_a = emb_a.to(torch.float32)
        emb_b = emb_b.to(torch.float32)
        if emb_a.shape != emb_b.shape:
            raise ValueError(
                f"Mismatched embedding shapes for cosine similarity ({key_a} vs {key_b})"
            )
        sims.append(
            torch.nn.functional.cosine_similarity(emb_a.unsqueeze(0), emb_b.unsqueeze(0)).item()
        )
    return np.array(sims)


def plot_cosine_distribution(cosine: np.ndarray, save_path: Path) -> None:
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.hist(cosine, bins=40, color="steelblue", alpha=0.8, edgecolor="black")
    ax.set_xlabel("Cosine similarity")
    ax.set_ylabel("Count")
    ax.set_title("Cosine similarity distribution")
    ax.grid(True, alpha=0.2)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.tight_layout()
    fig.savefig(save_path, dpi=200)
    plt.close(fig)


def plot_cosine_vs_redshift(
    cosine: np.ndarray,
    redshift: np.ndarray,
    save_path: Path,
) -> None:
    mask = ~np.isnan(redshift)
    if mask.sum() == 0:
        print("No valid redshift values available for cosine vs redshift plot.")
        return

    fig, ax = plt.subplots(figsize=(6, 4))
    ax.scatter(
        redshift[mask],
        cosine[mask],
        s=10,
        c=cosine[mask],
        cmap="magma",
        alpha=0.7,
        edgecolors="none",
    )
    ax.set_xlabel("Redshift")
    ax.set_ylabel("Cosine similarity")
    ax.set_title("Cosine similarity vs redshift")
    ax.grid(True, alpha=0.2)

    sorted_idx = np.argsort(redshift[mask])
    z_sorted = redshift[mask][sorted_idx]
    cos_sorted = cosine[mask][sorted_idx]
    window = max(5, int(len(z_sorted) * 0.05))
    if window % 2 == 0:
        window += 1
    if window < len(z_sorted):
        kernel = np.ones(window) / window
        smooth = np.convolve(cos_sorted, kernel, mode="valid")
        center = (window - 1) // 2
        ax.plot(z_sorted[center : center + len(smooth)], smooth, color="white", linewidth=2.0, alpha=0.8)

    fig.tight_layout()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(save_path, dpi=200)
    plt.close(fig)


def _nearest_neighbor_indices(embeddings: np.ndarray) -> np.ndarray:
    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
    norms[norms == 0] = 1e-9
    normalized = embeddings / norms
    similarity = normalized @ normalized.T
    np.fill_diagonal(similarity, -np.inf)
    return np.argmax(similarity, axis=1)


def compute_nearest_neighbor_agreement(
    emb_a: np.ndarray,
    emb_b: np.ndarray,
) -> tuple[np.ndarray, np.ndarray, float]:
    nn_a = _nearest_neighbor_indices(emb_a)
    nn_b = _nearest_neighbor_indices(emb_b)
    matches = nn_a == nn_b
    match_ratio = matches.mean() if matches.size else math.nan
    return matches, np.stack((nn_a, nn_b), axis=1), match_ratio


def plot_nn_agreement(matches: np.ndarray, save_path: Path) -> None:
    counts = np.array([matches.sum(), (~matches).sum()])
    labels = ["Same neighbor", "Different neighbor"]
    fig, ax = plt.subplots(figsize=(6, 4))
    bars = ax.bar(labels, counts, color=["seagreen", "salmon"], alpha=0.8)
    ax.set_ylabel("Number of objects")
    ax.set_title("Nearest-neighbor agreement")
    for bar, count in zip(bars, counts):
        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(int(count)), ha="center", va="bottom")
    ax.grid(axis="y", alpha=0.2)
    fig.tight_layout()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(save_path, dpi=200)
    plt.close(fig)


def parse_pair(value: str) -> tuple[str, str]:
    parts = [p.strip() for p in value.split(",") if p.strip()]
    if len(parts) != 2:
        raise argparse.ArgumentTypeError("Pair must contain exactly two embedding keys separated by a comma")
    return parts[0], parts[1]


def main(argv: Sequence[str] | None = None) -> None:
    parser = argparse.ArgumentParser(
        description="UMAP projections, cosine similarities, and nearest-neighbor diagnostics for embeddings",
    )
    parser.add_argument("--input", required=True, help="Path to embeddings .pt file")
    parser.add_argument("--figure", required=True, help="Path to save UMAP figure")
    parser.add_argument("--cosine-output", default=None, help="Optional path to save cosine similarities (.csv/.npy)")
    parser.add_argument("--cosine-figure", default=None, help="Optional path to save cosine histogram")
    parser.add_argument("--cosine-redshift-figure", default=None, help="Optional path for cosine vs redshift plot")
    parser.add_argument("--nn-figure", default=None, help="Optional path for nearest-neighbor agreement figure")
    parser.add_argument("--nn-report", default=None, help="Optional CSV path for nearest-neighbor pairs")
    parser.add_argument(
        "--cosine-pair",
        type=parse_pair,
        default=parse_pair(DEFAULT_PAIR),
        help=f"Embedding pair for cosine metrics (default: {DEFAULT_PAIR})",
    )
    parser.add_argument(
        "--nn-pair",
        type=parse_pair,
        default=parse_pair(DEFAULT_PAIR),
        help=f"Embedding pair for nearest-neighbor metrics (default: {DEFAULT_PAIR})",
    )
    parser.add_argument("--random-state", type=int, default=42, help="Random state for UMAP")

    args = parser.parse_args(argv)

    records = load_records(Path(args.input))

    embeddings = {}
    for key in EMBEDDING_KEYS:
        try:
            embeddings[key] = stack_embeddings(records, key)
        except ValueError:
            continue
    if not embeddings:
        raise SystemExit("No embeddings found in input file")

    coords_map = {
        key: compute_umap(array, random_state=args.random_state)
        for key, array in embeddings.items()
    }

    redshifts = np.array([rec.get("redshift", np.nan) for rec in records], dtype=float)
    colors = redshifts.copy()
    if np.isnan(colors).all():
        colors = None

    plot_umap_grid(coords_map, colors, Path(args.figure))

    key_a, key_b = args.cosine_pair
    if key_a not in embeddings or key_b not in embeddings:
        raise SystemExit("Embedding keys provided to --cosine-pair not found in data")
    cosine = compute_cosine_similarities(records, key_a, key_b)
    print(
        f"Cosine similarity ({key_a} vs {key_b}) -- mean: {cosine.mean():.4f}  std: {cosine.std():.4f}  "
        f"min: {cosine.min():.4f}  max: {cosine.max():.4f}"
    )

    if args.cosine_output:
        cosine_path = Path(args.cosine_output)
        cosine_path.parent.mkdir(parents=True, exist_ok=True)
        object_ids = [rec.get("object_id", "") for rec in records]
        if cosine_path.suffix.lower() == ".csv":
            with cosine_path.open("w", newline="") as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow(["object_id", f"cosine_{key_a}_vs_{key_b}"])
                for oid, cos_val in zip(object_ids, cosine):
                    writer.writerow([oid, f"{cos_val:.6f}"])
        else:
            np.save(cosine_path, cosine)
        print(f"Saved cosine similarities to {cosine_path}")

    if args.cosine_figure:
        plot_cosine_distribution(cosine, Path(args.cosine_figure))
        print(f"Saved cosine histogram to {args.cosine_figure}")

    if args.cosine_redshift_figure:
        plot_cosine_vs_redshift(cosine, redshifts, Path(args.cosine_redshift_figure))
        print(f"Saved cosine vs redshift figure to {args.cosine_redshift_figure}")

    if args.nn_figure or args.nn_report:
        nn_a, nn_b = args.nn_pair
        if nn_a not in embeddings or nn_b not in embeddings:
            raise SystemExit("Embedding keys provided to --nn-pair not found in data")
        matches, nn_pairs, match_ratio = compute_nearest_neighbor_agreement(
            embeddings[nn_a], embeddings[nn_b]
        )
        print(
            f"Nearest-neighbor agreement ({nn_a} vs {nn_b}): {matches.sum()} / {len(matches)} "
            f"(ratio={match_ratio:.3f})"
        )
        if args.nn_figure:
            plot_nn_agreement(matches, Path(args.nn_figure))
            print(f"Saved nearest-neighbor agreement figure to {args.nn_figure}")
        if args.nn_report:
            report_path = Path(args.nn_report)
            report_path.parent.mkdir(parents=True, exist_ok=True)
            object_ids = [rec.get("object_id", "") for rec in records]
            with report_path.open("w", newline="") as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow(["object_id", f"nn_{nn_a}", f"nn_{nn_b}", "match"])
                for idx, (nn_idx_a, nn_idx_b) in enumerate(nn_pairs):
                    writer.writerow(
                        [
                            object_ids[idx],
                            object_ids[nn_idx_a],
                            object_ids[nn_idx_b],
                            "True" if matches[idx] else "False",
                        ]
                    )
            print(f"Saved nearest-neighbor report to {report_path}")


if __name__ == "__main__":
    main()
